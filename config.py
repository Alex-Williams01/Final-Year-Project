# config.py
global TEXT_ID
global VIDEO_ID
global AUDIO_ID
global SHOW_ID
global SPEAKER_ID
global CONTEXT_ID
TEXT_ID = 0
VIDEO_ID = 1
AUDIO_ID = 2
SHOW_ID = 3
SPEAKER_ID = 4
CONTEXT_ID = 5

global TEXT_DIM
global VIDEO_DIM
global AUDIO_DIM
TEXT_DIM = 768
VIDEO_DIM = 2048
AUDIO_DIM = 283

global CONTEXT_HIDDEN
global TEXT_HIDDEN
global VIDEO_HIDDEN
global AUDIO_HIDDEN
global SPEAKER_HIDDEN
CONTEXT_HIDDEN = 32
TEXT_HIDDEN = 32
VIDEO_HIDDEN = 128
AUDIO_HIDDEN = 16
SPEAKER_HIDDEN = 4

global VIDEO_DROPOUT
global AUDIO_DROPOUT
global TEXT_DROPOUT
global POST_FUSION_DROPOUT
global SPEAKER_DROPOUT
global CONTEXT_DROPOUT
VIDEO_DROPOUT = 0.2
AUDIO_DROPOUT = 0.2
TEXT_DROPOUT = 0.2
SPEAKER_DROPOUT = 0.2
POST_FUSION_DROPOUT = 0.2
CONTEXT_DROPOUT = 0.2

global TEXT_INIT_WEIGHT
global VIDEO_INIT_WEIGHT
global AUDIO_INIT_WEIGHT
global SPEAKER_INIT_WEIGHT
global CONTEXT_INIT_WEIGHT
TEXT_INIT_WEIGHT = 1.0
VIDEO_INIT_WEIGHT = 1.0
AUDIO_INIT_WEIGHT = 1.0
CONTEXT_INIT_WEIGHT = 1.0
SPEAKER_INIT_WEIGHT = 1.0

global POST_FUSION_DIM
POST_FUSION_DIM = 32

global LEARNING_RATE
LEARNING_RATE = 5e-4

global WEIGHT_DECAY
WEIGHT_DECAY = 0.0

global EARLY_STOPPING
EARLY_STOPPING = 20

global DATA_PATH_JSON
DATA_PATH_JSON = "data/sarcasm_data_mustard.json"

global BERT_TARGET_EMBEDDINGS
BERT_TARGET_EMBEDDINGS = "data/bert-output.jsonl"

global BERT_CONTEXT_EMBEDDINGS
BERT_CONTEXT_EMBEDDINGS = "data/bert-output-context.jsonl"

global INDICES_FILE
INDICES_FILE = "data/split_indices.p"

global AUDIO_PICKLE
AUDIO_PICKLE = "data/audio_features.p"

global BATCH_SIZE
BATCH_SIZE = 32

global MODEL_PATH
MODEL_PATH= "saved/lfdnn-mustard-M.pth"

global MODEL_NAME
MODEL_NAME = 'weighted_fusion'

global RESULT_FILE
RESULT_FILE = "output/{}.json"

